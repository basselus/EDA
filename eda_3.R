
# Chargement des packages

packages = c("prettyR","gplots","binom","Epi", "psych")

package_check <- lapply(packages, FUN = function(x){
  
  if (!require(x, character.only=T)) {
    
    install.packages(x, dependencies = T)  
    library(x, character.only=T)
  }
  
})


# chargement des fichiers de donn√©es 


sp=read.csv("sp1.csv", header = T, sep = ";", stringsAsFactors = T)
dim(sp)
str(sp)
attach(sp)

sp_2=read.csv("sp2.csv", header = T, sep = ";", stringsAsFactors = T)
dim(sp_2)
str(sp_2)
attach(sp_2)


repdat=read.csv("repdat.csv", header = T, sep = ";", stringsAsFactors = T)
dim(repdat)
str(repdat)
attach(repdat)



# DISTRIBUTION DES VARIABLES ET REPRESENTATIONS GRAPHIQUES

#Repr√©sentation graphique de professions:

barplot(table(prof))
pie(table(prof))


#Repr√©sentation d'une variable quantitative discr√®te

hist(age, col="blue", main = "distribution de l'age", xlab = "√¢ge", ylab = "fr√©quences")
boxplot(age, col = "lightgreen", xlab = "√¢ge")

# Les BAM sont utiles pour repr√©senter la distribution d'une variable quantitative 
# en fonction de sous-groupes :
#exemple distribution de l'age en fonction de la variable rs(recherche de sensation)

boxplot(age~rs, xlab="recherche de sensations", ylab="age", 
        main="distribution de rs selon l'age", col=c("red", "yellow", "green"))


# Distribution conjointe de 2 variables al√©atoires quantitatives

plot(n.enfant~age) 

# Plus un d√©tenu est √¢g√©, plus son nombre d'enfants est √©lev√©

# Pour √©viter la superposition des points on peut utiliser la plot jitter

plot(jitter(age), jitter(n.enfant))


# Repr√©sentation temporelle d'une variable al√©atoire quantitative avec la fonction plotmeans
install.packages("gplots")
library(gplots)
plotmeans(HDRS~VISIT, barcol = "green")

# On note la progression de l'√©tat symptomatique des patients au fil du temps

# Mesure de la variabilit√© du ph√©nom√®ne d'un sujet √† l'autre
# On utilise la fonction interaction.plot:

interaction.plot(VISIT, # variable temporelle
                 NUMERO, # variable qui indique chaque sujet   
                 HDRS,  # variable repr√©sent√©e
                 lty =6, legend = FALSE)


# MESURES DE POSITION ET DE DISPERSION

# les mesures agr√©g√©es servent √† synth√©tiser l'information (exemple moyenne et √©cart-type)
# pour une variable cat√©gorielle il s'agit de lister les pourcentages de toutes les modalit√©s
# pour une variable il faut prendre d'autres param√®tres comme la moyenne et la m√©diane
# moyenne : baricentre = sens physique
# dans une distribution sym√©trique mean=median
# dans le cas contraire il ya des diff√©rences entre les 2
# Ecarts interquartiles
# Dans une distribution normale , l'intervalle :[m-e.t., m+e.t.] contient approximativement 2/3 des donn√©es
# 
# En pratique : on utilise la fonction summary

summary(sp)

# Pour une visualisation plus commode on utilise la fonction describe du package (prettyR)

install.packages("prettyR")
library(prettyR)
describe(sp) # elle ne pr√©sente pas les quartiles, le minimum et le maximum (ceux-ci permettent de d√©tecter les valeurs aberrantes)

# On peut ajouter ces param√®tres avec :

describe(sp, num.desc = c("mean", "sd", "median", "min", "max", "valid.n"))

# GESTION DES VARIABLES DANS UN DATAFRAME

# explications sur l'interface de Rstudio 

# On va utiliser le fichier sp2

str(sp_2)
dim(sp_2)
names(sp_2)
summary(sp_2)
summary(age)
describe(sp_2)

# Explication sur le rÙle de les fonctions attach et detach

sp_2$age[2]  # On afficche le deuxi√®me individu de la variable age
sp_2$age[3:10] # On affiche de la 1ere √† la 10eme observation
head(sp_2$age, n=10) # √©quivalent √† la pr√©c√©dente
min(sp_2$age)  # on a NA en retour car il ya des valeurs manquantes
min(sp_2$age, na.rm = TRUE) # Option pour √©viter le d√©compte des valeurs manquantes
unique(sp_2$abus) # Pour afficher les niveaux ou modalit√©s de la variable abus
length(sp_2$abus) # nombre d'observations d'une variable
nrow(sp_2)   # nombre de lignes
ncol(sp_2)   # nombre de colonnes
table(sp_2$rs, useNA = "always") # ajouter l'option usena pour s'assurer de compter les valeurs manquantes
summary(sp_2$abus)

# On va traiter la variable abus comme une variable cat√©gorielle (factor)

class(sp_2$abus)
sp_2$abus=as.factor(as.integer(sp_2$abus))
sp_2$abus=factor(sp_2$abus, levels = c("0","1"), labels = c("Non","Oui"))
levels(sp_2$abus)
table(sp_2$abus, useNA = "always")

# Variable nombre d'enfants

names(sp_2)
class(sp_2$n.enfant)
summary(sp_2$n.enfant)
table(sp_2$n.enfant)
table(sp_2$n.enfant > 4)

# On cr√©e une variable nombre d'enfants sup√©rieur √† 4

sp_2$n.enfant.cat=factor(sp_2$n.enfant)
levels(sp_2$n.enfant.cat)
nlevels(sp_2$n.enfant.cat)  # v√©rification du nombre de niveaux

# Cr√©ation d'une cat√©gorie 5 enfants et +

levels(sp_2$n.enfant.cat)[6:13]<- "5+"
table(sp_2$n.enfant.cat)

# on le fait avec la fonction ifelse en cr√©ant une nouvelle variable

sp_2$nenf_bis=ifelse(sp_2$n.enfant>=5, "oui", "non")
head(sp_2$nenf_bis)
table(sp_2$nenf_bis)

# Sauvegarder le fichier en format R

save(sp_2, file = "sp_v1.rda")  # il sera charg√© dans notre r√©pertoire de travail

# On sauve l'historique des commandes

savehistory(file = "commandes_1.R")


# INDEXATIONS AVEC CRITERES D'OBSERVATION

# Rechargement du dernier fichier de travail

load("sp_v1.rda")
names(sp_2)

# indexation de la 1ere observation et de la 1ere variable

sp_2[1,1]
sp_2[1,"prof"] # obs 1 , variable prof
sp_2[1:2,c(3,4)] # obs 1 √† 2, variable 3 √† 4

# On cherche les professions agriculteurs

head(sp_2$prof=="agriculteur")
table(sp_2$prof=="agriculteur")  # solution 1

head(sp_2$prof[which(sp_2$prof %in% c("agriculteur"))]) # solution 2 avec which
which(sp_2$prof=="agriculteur")   # renvoi des num√©ros d'observation

# On indexe les valeurs de la variable √¢ge pour lesquels profession==agriculteur

sp_2$age[which(sp_2$prof=="agriculteur")]

# usage de la commande subset

attach(sp_2)
subset(sp_2, prof=="agriculteur", age)  # dans l'ordre la base, le filtre et la variable
subset(sp_2, prof=="agriculteur", c(2,5)) # on √©tend la s√©lection √† plusieurs variables
subset(sp_2, prof=="agriculteur", 1:6)

# Combinaison de 2 filtres (ouvriers et nombre d'enfants sup√©rieur √† 2)

subset(sp_2, prof=="ouvrier" & n.enfant>2, c(age, duree, discip, n.enfant))

# ajout de filtres en excluant les NA sur la variable dur√©e

subset(sp_2, prof=="ouvrier" & n.enfant>2 & complete.cases(duree), c(age, duree, discip, n.enfant))


# On stocke les r√©sultats de la variable nenfantcat dans une table et on effectue des op√©rations

tab<-table(n.enfant.cat)
sum(tab)
tab/sum(tab)

# On peut faire la m√™me chose avec les fonctions round et prop.table

round(prop.table(tab), digits = 2) 


# Repr√©sentation graphique pour la variable cat√©gorielle (barplot)

barplot(prop.table(tab)*100, col = "blue", main = "diagramme en b√¢ton")

# On ajuste les labels verticaux

barplot(prop.table(tab)*100, ylim = c(0,30), las=1,  col = "blue", main = "diagramme en b√¢ton")


# Repr√©sentation graphique pour la variable num√©rique (histogramme)

summary(age)
hist(age, col = "blue", main = "distribution de la variable age")

  # Changement du nombre de classes:
  hist(age, nclass=8, col = "blue", main = "distribution de la variable age")
  
  # ajout des densit√©s non param√©triques
  hist(age, nclass=8, probability = TRUE, las=1)
  lines(density(sp_2$age, na.rm = TRUE))
  
  
# INTERVALLES DE CONFIANCE
  
# passage de l'√©chelle de l'√©chantillon √† celle de la population: l'objectif est de g√©n√©raliser 
  #la mesure d'un param√®tre (moyenne, pourcentages, variances , etc.)
  # si on a un param√®tre avec distribution normale, le param√®tre estim√© par "m" et "e.t",
  # L"intevalle de confiance  √† 95% du param√®tre est de :
                  #  [m-1.96*e.t.,m+1.96*e.t.]
  
  library(prettyR)
  describe(sp$age)
  summary(sp$age)
  borne_inf=38.9-1.96*13.28/sqrt(799)
  borne_sup=38.9+1.96*13.28/sqrt(799)
  borne_inf
  borne_sup
  
  # Un intervalle de confiance √† 95% de l'√¢ge est compris entre 38 et 40 ans
  
  # Estimation automatique √† l'aide de R : on estime l'intervalle de confiance en utilisant toutes les m√©thodes
  
  install.packages("binom")
  library(binom)
  binom.confint(3,10, methods = "all") # 3 est le nombre d'individus tir√©s
                                       #  10 est la taille de l'√©chantillon
                                       #  "all" sp√©cifie de prendre toutes les m√©thodes d'estimation
  
  # Il faut choisir la m√©thode "exact" avec un intervalle de confiance √† 7 et 65%
  
  # quand la taille de l'√©chantillon s'accroit, toutes les m√©thodes convergent vers la m√™me valeur
  
  # On change la taille de l'√©chantillon et le nombre de sujets tir√©s pour v√©rifier cela
  
  binom.confint(300,1000, methods = "all") 
  
  # les estimations convergent vers des valeurs identiques
  
  # COEFFICIENTS DE CORRELATION
  # La liaison entre 2 variable est dite forte quand la connaissance
  # de la valeur de l'une donne une indication sur la valeur de l'autre
  # degr√© de liaison : entre -1 et 1 (exemple : la forte majorit√© de la population 
  # carc√©rale est d'origine noire ou arabe:
    # 1 -corr√©lation entre ces deux ph√©nom√®nes = oui
    # 2 - causalit√©  = non (cequi reviendrait √† dire que les noir et les arabes sont des d√©linquants))
  
 # r=0 ; il y a absence de corr√©lation sssi les 2 variables suivent une loi normale  
  
  
  # Repr√©sention graphique de la liaison entre age et nombre d'enfants
  
  plot(jitter(sp$age), jitter(sp$n.enfant))
  
  # calcul de la corr√©lation
  
  cor(sp$age,sp$n.enfant, use = "complete.obs")
  
# LIAISON ENTRE 2 VARIABLES BINAIRES (ODDS RATIO ET RISQUE RELATIF)
  
  # exemple :maladie vs facteur de risque
  # association entre √©vitement du danger(ed) et trouble d√©pressif (dep.cons)
  names(sp)
  sp$ed_2=ifelse(sp$ed>2, 1, 0)
  str(sp)  
  table(sp$ed_2, sp$ed, deparse.level = 2, useNA = "always")  
  
  #calcul odds ratio
  install.packages("Epi")
  library(Epi)
  twoby2(1-sp$ed_2, 1-sp$dep.cons)

  tab=table(sp$dep.cons)  
  round(prop.table(tab), digits = 3) #  √† 40% , nous ne sommes pas en pr√©sence d'une
  # pathologie rare, donc inutile de faire usage de l'odds ratio . On se focalise sur le 
  # risque relatif qui est √©gal √† 2 : donc 2 fois plus de chance d'avoir un √©tat d√©pressif
  # quand on a un √©vitement du danger √©lev√© par rapport au contraire

 sp[c(20, 221, 342, 446, 531),]
 tab=table(sp$prof)
 round(prop.table(tab)*100, digits = 2)
 t1=subset(sp,sp$age>=20 & sp$age<=30)


  # TESTS STATISTIQUES
 # valeur de p pour savoir si les ph√©nom√®nes ne sont pas dus au hasard
 # p d√©pend de la taille des √©chantillons
 # Neyman et Pearson = on d√©termine le seuil de risque a priori (prise de d√©cision importante :exemple des tests m√©dicamenteux)
 # Fischer = on calcule la valeur de p a posteriori (plus utilis√© dans les autres cas)
 
 # TEST DU CHI2
 sp$ed_bis<-ifelse(sp$ed>2, 1, 0)
 names(sp)
 # On croise l'√©vitement du danger et le diagnostic de d√©pression et l'√©vitement du danger
 tab=table(sp$ed_bis, sp$dep.cons, deparse.level = 2, useNA = "always")
 tab_2=table(sp$ed_bis, sp$dep.cons, deparse.level = 2)
 
  prop.table(tab_2, 1) # On √©dite le % de d√©pression selon le fait d'avoir ou non un haut niveau d'ed.
  prop.table(tab_2, 2) # On √©dite le % de l'inverse
  
  #usage du Test de chi2 avec la fonction chisq.test
  chisq.test(sp$ed_bis, sp$dep.cons, correct = FALSE) # correct=false Pour √©viter le test de correction Robuste)
  
  #Avec un p=10 puisance -12, tr√®s largement inf√©rieur √† 5% : donc avec certitude, le hasard ne peut pas 
  # √† lui tout seul une telle diff√©rence de pr√©valence de d√©pression
  
  #Test alternatif de Fisher dans le cas o√π les conditions de validit√© du chi2 ne sont pas respect√©s(petits √©chantillons)
  fisher.test(sp$ed_bis, sp$dep.cons)
  
  
  #COMPARAISON DE DEUX MOYENNES
  # test t de student
  # conditions de validit√© : 
    # 1: au moins 30 individus dans chaque groupe d'observations
    # 2 :la variable √©tudi√©e doit suivre une loi normale
    # 3 : √©galit√© des variances entre les groupes consid√©r√©s
  # exemple : compraraison de l'√¢ge(age) en fonction de l'√©vitement du danger(ed)
  
  # distribution de la variable age : ce n'est pas tout √† fait une loi normale
  hist(sp$age, col = "blue")
  
  # On essaye un diagramme de normalit√©
  qqnorm(sp$age);qqline(sp$age)
  
  # Il ya un √©cart √† la normalit√© sur la partie inf√©rieure gauche du graphe.
  # Test d√©galit√© des variances (ou des ET) dans les groupes √† comparer
  by(sp$age, sp$ed_bis, sd, na.rm=T)
  # La valeur des ET dans les groupes de la variable ed_bis est quasiment la m√™me
  # quand un ET est >= √† 1,5 fois l'autre ET √ßa compromet la pertinence de l'usage du T de student
  
  # calcul du test t de student
  
  t.test(sp$age~sp$ed_bis, var.equal=TRUE)
  # on a p>0.05 : donc on ne peut pas dire qu'il ya une diff√©rence significative d'age entre les 
  # diff√©rents groupes de la variable ed_bis
  
  
  # Si les conditions d'usage de t student ne sont pas r√©unies, on peut utiliser les tests
  # de Wilcoxon ou de Man withney
  
  wilcox.test(sp$age, sp$ed_bis)

  #TEST DE NULLITE DE CORRELATION de Pearson ENTRE 2 VARIABLES:
    # condition: il faut que l'une au moins des 2 variables suive une loi normale
  # Exemple : corr√©lation entre age et recherche de sensations
  
  cor.test(sp$age,sp$rs, method = "pearson")
  # p est tr√®s faible : donc corr√©lation tr√®s significativement non nulle
  # cor = -0.22 donc corr√©lation n√©gative entre age et recherche de sensations
  # int conf du coefficient de corr√©lation : 95% de chances que cor soit contenu entre :
    # -0.2922516  et -0.1509579 dans la population totale
  
  # Test de nullit√© du coef de corr√©lation de Spearman : test bas√© sur les rangs des individus des deux variables
  # Ce test est donc plus robuste car on fait la corr√©lation des rangs des individus des 2 vars 
  
  cor.test(sp$age,sp$rs, method = "spearman")
 # le p est tr√®s petit et la corr√©lation est significativement n√©gative
  
  #RESUME :
    # WILCOXON : usage dans des cas de non normalit√© de la variable
    # SPEARMAN : usage quand aucune des 2 vars ne suit une loi normale : a posteriori on 
      # ne peut plus utiliser les techniques statistiques qui n√©cessitent la normalit√© des variables
      # il faut toujours a priori v√©rifier la normalit√© de la variable avant de se lancer dans un choix de m√©thode
  
  # COMPARAISON D'UNE MOYENNE A UNE REFERENCE
  # quand on connait la moyenne de r√©f√©rence d'une variable dans une population de r√©f√©rence
  t.test(sp$age, mu=24)
  
  # TESTS APPARIES : MESURES AVANT ET APRES D'UN PHENOMENE
  # on suit un groupe d'individus et on mesure le ph√©nom√®ne avant et apr√®s
  
  
  mcnemar.test("variable avant", "variable apr√®s")
  t.test("variable avant", "variable apr√®s", paired = TRUE)
  
  # TESTS D'ASSOCIATION : GRAPHIQUES BIVARIES
  
  load("sp_v1.rda")
  table(sp_2$subst.cons)
  tab=table(sp_2$subst.cons, sp_2$abus)  
  prop.table(tab, margin = 1) # Les effectifs sont rapport√©s aux totaux lignes    
  prop.table(tab, margin = 2) # Les effectifs sont rapport√©s aux totaux colonnes
  
# M√™me chose que la fonction prop.table
xtabs(~ subst.cons+abus, sp_2)

# barplot pour afficher les modalit√©s
barplot(xtabs(~ subst.cons+abus, sp_2), beside = TRUE)

# Test du chi2 entre les 2 vars qualitatives
res=chisq.test(tab)

# Affichage des effectifs observ√©s dans l'objet res
res$observed

# Affichage des effectifs attendus dans l'objet res
res$expected

# Test de Fisher
fisher.test(tab)

# Description du comportement de la variable age en fonction des 2 modalit√©s de subst.cons
tapply(sp_2$age, sp_2$subst.cons, mean, na.rm=TRUE) # comportement de l'age moyen en fonction de des deux modalit√©s



# Test de student pour comparer les moyennes d'age selon les modalit√©s 0 et 1 de subst.cons
t.test(sp_2$age[sp_2$subst.cons==0],sp_2$age[sp_2$subst.cons==1] , var.equal = TRUE)

# M√™me r√©sultat avec le t.test (on n'est pas oblig√© de pr√©fixer la var avec le nom de la table)
t.test(age~subst.cons, sp_2)
aggregate(age~subst.cons, sp_2, mean) # age moyen distribu√© selon les 2 modalit√©s de subst.cons (m√™me chose que tapply, sauf qu'on n'a pas besoin de faire na.rm=true)

# Repr√©sentation graphique et distributions conditionnelles avec boxplot
boxplot(sp_2$age, sp_2$subst.cons, col = c("blue", "green"))

library(gplots)

with(sp_2, tapply(sp_2$age, sp_2$subst.cons, mean, na.rm=TRUE))


#******************************************
#REGRESSION LINEAIRE SIMPLE
#******************************************

# d√©finition droite de r√©gression : droite qui minimise la somme des carr√©s des distances entre y et √ø
plot(sp_2$age, sp_2$dur.interv)

library(psych)
